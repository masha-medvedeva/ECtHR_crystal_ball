{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all necessary imports\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "import glob,re, os, sys, random\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "from nltk.corpus import stopwords\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(starts, ends, cases, violation):\n",
    "    facts = []\n",
    "    D = []\n",
    "    years = []\n",
    "    for case in cases:\n",
    "        contline = ''\n",
    "        year = 0\n",
    "        with open(case, 'r') as f:\n",
    "            for line in f:\n",
    "                dat = re.search('^([0-9]{1,2}\\s\\w+\\s([0-9]{4}))', line)\n",
    "                if dat != None:\n",
    "                    year = int(dat.group(2))\n",
    "                    break\n",
    "            if year>0:\n",
    "                years.append(year)\n",
    "                wr = 0\n",
    "                for line in f:\n",
    "                    if wr == 0:\n",
    "                        if re.search(starts, line) != None:\n",
    "                            wr = 1\n",
    "                    if wr == 1 and re.search(ends, line) == None:\n",
    "                        contline += line\n",
    "                        contline += '\\n'\n",
    "                    elif re.search(ends, line) != None:\n",
    "                        break\n",
    "                facts.append(contline)\n",
    "    for i in range(len(facts)):\n",
    "        D.append((facts[i], violation, years[i])) \n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_parts(train_path, violation, part): #extract text from different parts\n",
    "    cases = glob.glob(train_path)\n",
    "\n",
    "    facts = []\n",
    "    D = []\n",
    "    years = []\n",
    "    \n",
    "    if part == 'relevant_law': #seprarte extraction for relevant law\n",
    "        for case in cases:\n",
    "            year = 0\n",
    "            contline = ''\n",
    "            with open(case, 'r') as f:\n",
    "                for line in f:\n",
    "                    dat = re.search('^([0-9]{1,2}\\s\\w+\\s([0-9]{4}))', line)\n",
    "                    if dat != None:\n",
    "                        year = int(dat.group(2))\n",
    "                        break\n",
    "                if year> 0:\n",
    "                    years.append(year)\n",
    "                    wr = 0\n",
    "                    for line in f:\n",
    "                        if wr == 0:\n",
    "                            if re.search('RELEVANT', line) != None:\n",
    "                                wr = 1\n",
    "                        if wr == 1 and re.search('THE LAW', line) == None and re.search('PROCEEDINGS', line) == None:\n",
    "                            contline += line\n",
    "                            contline += '\\n'\n",
    "                        elif re.search('THE LAW', line) != None or re.search('PROCEEDINGS', line) != None:\n",
    "                            break\n",
    "                    facts.append(contline)\n",
    "        for i in range(len(facts)):\n",
    "            D.append((facts[i], violation, years[i]))\n",
    "        \n",
    "    if part == 'facts':\n",
    "        starts = 'THE FACTS'\n",
    "        ends ='THE LAW'\n",
    "        D = extract_text(starts, ends, cases, violation)\n",
    "    if part == 'circumstances':\n",
    "        starts = 'CIRCUMSTANCES'\n",
    "        ends ='RELEVANT'\n",
    "        D = extract_text(starts, ends, cases, violation)\n",
    "    if part == 'procedure':\n",
    "        starts = 'PROCEDURE'\n",
    "        ends ='THE FACTS'\n",
    "        D = extract_text(starts, ends, cases, violation)\n",
    "    if part == 'procedure+facts':\n",
    "        starts = 'PROCEDURE'\n",
    "        ends ='THE LAW'\n",
    "        D = extract_text(starts, ends, cases, violation)\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_cross_val(Xtrain, Ytrain, vec, c): #Linear SVC model cross-validation\n",
    "    print('***10-fold cross-validation***')\n",
    "    pipeline = Pipeline([\n",
    "        ('features', FeatureUnion(\n",
    "            [vec],\n",
    "        )),\n",
    "        ('classifier', LinearSVC(C=c))\n",
    "        ])\n",
    "    Ypredict = cross_val_predict(pipeline, Xtrain, Ytrain, cv=10) #10-fold cross-validation\n",
    "    evaluate(Ytrain, Ypredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_test(Xtrain, Ytrain, Xtest_v, Ytest_v, vec, c): #test on 'violations' test set\n",
    "    pipeline = Pipeline([\n",
    "        ('features', FeatureUnion([vec]\n",
    "        )),\n",
    "        ('classifier', LinearSVC(C=c))\n",
    "        ])\n",
    "    pipeline.fit(Xtrain, Ytrain)\n",
    "    print('***testing on violation testset***')\n",
    "    Ypredict = pipeline.predict(Xtest_v)\n",
    "    evaluate(Ytest_v, Ypredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(Ytest, Ypredict): #evaluate the model (accuracy, precision, recall, f-score, confusion matrix)\n",
    "        print('Accuracy:', accuracy_score(Ytest, Ypredict) )\n",
    "        print('\\nClassification report:\\n', classification_report(Ytest, Ypredict))\n",
    "        print('\\nCR:', precision_recall_fscore_support(Ytest, Ypredict, average='macro'))\n",
    "        print('\\nConfusion matrix:\\n', confusion_matrix(Ytest, Ypredict), '\\n\\n_______________________\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(part, vec, c): #run tests\n",
    "    \n",
    "    print('Trained on *' + part + '* part of the cases')\n",
    "    \n",
    "    v = extract_parts(path+'train/'+article+'/violation/*.txt', 'violation', part)\n",
    "    nv = extract_parts(path+'train/'+article+'/non-violation/*.txt', 'non-violation', part)\n",
    "    trainset =v+nv\n",
    "    shuffle(trainset)\n",
    "\n",
    "    Xtrain = [i[0] for i in trainset]\n",
    "    Ytrain = [i[1] for i in trainset]\n",
    "    \n",
    "    #test set with violations only\n",
    "    if article == 'Article14':\n",
    "        test = extract_parts('./test_violations/'+article+'/*.txt', 'non-violation', part)\n",
    "    else:\n",
    "        test = extract_parts('./test_violations/'+article+'/*.txt', 'violation', part)\n",
    "    Xtest_v = [i[0] for i in test]\n",
    "    Ytest_v = [i[1] for i in test]\n",
    "\n",
    "\n",
    "    print('Training on', Ytrain.count('violation'),'+', Ytrain.count('non-violation'), '=', Ytrain.count('violation') + Ytrain.count('non-violation'), 'cases', '\\nCases available for testing(violation):', Ytest_v.count('violation'))\n",
    "    #train_model_test(Xtrain, Ytrain, Xtest_v, Ytest_v, vec, c)\n",
    "    train_model_cross_val(Xtrain, Ytrain, vec, c) #use for cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ##INDICATE THE PATH TO THE DATA\n",
    "    #path = '~/Documents/ECtHR_crystal_ball/'\n",
    "    path = '../../crystal_ball_data/'\n",
    "    articles = ['Article2', 'Article3', 'Article5', 'Article6', 'Article8', 'Article10', 'Article11', 'Article13', 'Article14']\n",
    "    for article in articles: #the parameters were determined using grid-search\n",
    "        print (article)\n",
    "        if article == 'Article2':\n",
    "            vec = ('wordvec', TfidfVectorizer(analyzer = 'word', ngram_range = (3,4), binary = False, lowercase = True, min_df = 2, norm = 'l2', stop_words = None, use_idf = True))\n",
    "            c = 0.1\n",
    "            run_pipeline('procedure+facts', vec, c)\n",
    "        if article == 'Article3':\n",
    "            vec = ('wordvec', TfidfVectorizer(analyzer = 'word', binary = True,  lowercase = True,  min_df = 1,  ngram_range = (1,1),  norm = None,  stop_words = None,  use_idf = True))\n",
    "            c = 0.1\n",
    "            run_pipeline('facts', vec, c)\n",
    "        if article == 'Article5':\n",
    "            vec = ('wordvec', TfidfVectorizer(analyzer = 'word', binary = True,  lowercase = True,  min_df = 3,  ngram_range = (1, 1),  norm = 'l2',  stop_words = None,  use_idf = True))\n",
    "            c = 1\n",
    "            run_pipeline('facts', vec, c) \n",
    "        if article == 'Article6':\n",
    "            vec = ('wordvec', TfidfVectorizer(analyzer = 'word', binary = True,  lowercase = True,  min_df = 2,  ngram_range = (2,4),  norm = 'l2',  stop_words = None,  use_idf = True))\n",
    "            c = 5\n",
    "            run_pipeline('procedure+facts', vec, c)\n",
    "        if article == 'Article8':\n",
    "            vec = ('wordvec', TfidfVectorizer(analyzer = 'word', binary = True,  lowercase = True,  min_df = 1,  ngram_range = (3, 3),  norm = 'l2',  stop_words = None,  use_idf = False))\n",
    "            c = 1\n",
    "            run_pipeline('facts', vec, c)\n",
    "        if article == 'Article10':\n",
    "            vec = ('wordvec', TfidfVectorizer(analyzer = 'word', binary = False,  lowercase = False,  min_df = 1,  ngram_range = (1, 1),  norm = 'l2',  stop_words = None,  use_idf = False))\n",
    "            c = 5\n",
    "            run_pipeline('procedure+facts', vec, c)\n",
    "        if article == 'Article11':\n",
    "            vec = ('wordvec', TfidfVectorizer(analyzer = 'word', binary = False,  lowercase = True,  min_df = 2,  ngram_range = (1, 1),  norm = 'l1',  stop_words = 'english',  use_idf = False))\n",
    "            c = 1\n",
    "            run_pipeline('procedure', vec, c)\n",
    "        if article == 'Article13':\n",
    "            vec = ('wordvec', TfidfVectorizer(analyzer = 'word', binary = False,  lowercase = True,  min_df = 1,  ngram_range = (1, 2),  norm = 'l2',  stop_words = None,  use_idf = True))\n",
    "            c = 5\n",
    "            run_pipeline('procedure+facts', vec, c)\n",
    "        if article == 'Article14':\n",
    "            vec = ('wordvec', TfidfVectorizer(analyzer = 'word', binary = True,  lowercase = True,  min_df = 3,  ngram_range = (1, 1),  norm = 'l2',  stop_words = 'english',  use_idf = True))\n",
    "            c = 5\n",
    "            run_pipeline('procedure+facts', vec, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
